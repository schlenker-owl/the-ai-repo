# ======================================================================
# Qwen-0.5B  •  DoRA + KL SFT  •  FAST probe
# ----------------------------------------------------------------------
# WHEN TO USE
# - You want DoRA’s stability + a small KL to the base policy
#   (often the most robust small-data setup).
# ======================================================================

base_model: "Qwen/Qwen2.5-0.5B-Instruct"
dataset_path: "data/sft/spirit_chatml.jsonl"
system_prompt: "You are a compassionate, practical spiritual coach. Be concise, kind, and useful."
output_dir: "outputs/qwen05b_fast_dora_kl"

# Fast probe knobs
max_steps: 60
learning_rate: 5.0e-5      # slightly lower to play nice with KL
batch_size: 1
grad_accum: 8
max_seq_len: 512
print_every_steps: 5
log_wandb: false

# LoRA/DoRA
lora_r: 16
lora_alpha: 32
lora_dropout: 0.05
lora_target_mode: "attn_mlp"
use_dora: true              # ✅ DoRA ON

# KL-SFT
kl_lambda: 0.03             # start lower than KL-only lane; increase if needed
kl_tau: 1.0

# Fast shortcuts
ablate_examples: 96
ablate_seed: 42
max_minutes: 10

# Early stop (train-loss plateau)
early_stop_patience: 15
early_stop_min_delta: 0.003
early_stop_window: 5
early_stop_min_steps: 100

# Eval-loss early stop (off for fast)
eval_early_stop: false
eval_steps: 100
eval_patience: 5

# QoL
max_grad_norm: 1.0

# Post-train quick eval
eval_after_train: false
